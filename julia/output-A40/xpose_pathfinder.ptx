// PTX CompilerJob of MethodInstance for xpose_kernel(::CuDeviceVector{Int4x8, 1}, ::CuDeviceVector{Int4x8, 1}, ::CuDeviceVector{Int32, 1}) for sm_86, minthreads=512, blocks_per_sm=1

//
// Generated by LLVM NVPTX Back-End
//

.version 8.1
.target sm_86
.address_size 64

	// .globl	_Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE // -- Begin function _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE
                                        // @_Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE
.visible .entry _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE(
	.param .align 8 .b8 _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_0[16],
	.param .align 8 .b8 _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_1[32],
	.param .align 8 .b8 _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_2[32],
	.param .align 8 .b8 _Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_3[32]
)
.reqntid 512, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<102>;
	.reg .b64 	%rd<14>;

// %bb.0:                               // %conversion
	ld.param.u64 	%rd1, [_Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_1];
	ld.param.u64 	%rd2, [_Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_2];
	ld.param.u64 	%rd4, [_Z12xpose_kernel13CuDeviceArrayI6Int4x8Li1ELi1EES_IS0_Li1ELi1EES_I5Int32Li1ELi1EE_param_3];
	mov.u32 	%r12, %tid.x;
	mov.u32 	%r13, %ctaid.x;
	shl.b32 	%r14, %r13, 9;
	mov.u32 	%r15, %tid.y;
	shl.b32 	%r16, %r15, 5;
	or.b32  	%r17, %r14, %r12;
	or.b32  	%r18, %r17, %r16;
	mul.wide.u32 	%rd5, %r18, 4;
	add.s64 	%rd3, %rd4, %rd5;
	mov.u32 	%r19, 1;
	st.global.u32 	[%rd3], %r19;
	shr.u32 	%r20, %r12, 4;
	shl.b32 	%r21, %r12, 1;
	and.b32  	%r22, %r21, 2;
	or.b32  	%r23, %r22, %r20;
	shl.b32 	%r24, %r23, 5;
	and.b32  	%r25, %r21, 28;
	shl.b32 	%r26, %r15, 8;
	and.b32  	%r27, %r26, 256;
	shl.b32 	%r28, %r15, 7;
	and.b32  	%r1, %r28, 1792;
	or.b32  	%r29, %r24, %r25;
	or.b32  	%r30, %r27, %r14;
	or.b32  	%r2, %r30, %r29;
	or.b32  	%r31, %r27, %r29;
	or.b32  	%r32, %r31, 128;
	add.s32 	%r3, %r32, %r14;
	cvt.u16.u32 	%rs3, %r12;
	and.b16  	%rs1, %rs3, 16;
	and.b16  	%rs2, %rs3, 2;
	shl.b32 	%r33, %r15, 6;
	and.b32  	%r34, %r33, 64;
	shl.b32 	%r35, %r12, 4;
	and.b32  	%r36, %r35, 48;
	shl.b32 	%r37, %r13, 7;
	shl.b32 	%r38, %r15, 11;
	and.b32  	%r39, %r38, 28672;
	and.b32  	%r40, %r12, 12;
	or.b32  	%r41, %r20, %r40;
	or.b32  	%r4, %r41, %r39;
	or.b32  	%r42, %r34, %r36;
	or.b32  	%r5, %r42, %r37;
	shl.b32 	%r43, %r15, 4;
	and.b32  	%r44, %r43, 16;
	shl.b32 	%r45, %r12, 2;
	and.b32  	%r46, %r45, 12;
	shl.b32 	%r47, %r13, 5;
	or.b32  	%r48, %r44, %r46;
	or.b32  	%r6, %r48, %r47;
	mov.u32 	%r100, 0;
	setp.eq.s16 	%p1, %rs2, 0;
	setp.eq.s16 	%p2, %rs1, 0;
	mov.u32 	%r101, %r100;
LBB0_1:                                 // %L94
                                        // =>This Inner Loop Header: Depth=1
	or.b32  	%r49, %r101, %r1;
	shl.b32 	%r50, %r49, 16;
	or.b32  	%r51, %r50, %r2;
	mul.wide.u32 	%rd6, %r51, 4;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.v4.u32 	{%r52, %r53, %r54, %r55}, [%rd7];
	add.s32 	%r56, %r3, %r50;
	mul.wide.s32 	%rd8, %r56, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.v4.u32 	{%r57, %r58, %r59, %r60}, [%rd9];
	selp.b32 	%r61, %r54, %r52, %p2;
	shfl.sync.bfly.b32	%r62, %r61, 16, 31, -1;
	selp.b32 	%r63, %r52, %r62, %p2;
	selp.b32 	%r64, %r62, %r54, %p2;
	selp.b32 	%r65, %r55, %r53, %p2;
	shfl.sync.bfly.b32	%r66, %r65, 16, 31, -1;
	selp.b32 	%r67, %r53, %r66, %p2;
	selp.b32 	%r68, %r66, %r55, %p2;
	selp.b32 	%r69, %r59, %r57, %p2;
	shfl.sync.bfly.b32	%r70, %r69, 16, 31, -1;
	selp.b32 	%r71, %r57, %r70, %p2;
	selp.b32 	%r72, %r70, %r59, %p2;
	selp.b32 	%r73, %r60, %r58, %p2;
	shfl.sync.bfly.b32	%r74, %r73, 16, 31, -1;
	selp.b32 	%r75, %r58, %r74, %p2;
	selp.b32 	%r76, %r74, %r60, %p2;
	selp.b32 	%r77, %r71, %r63, %p1;
	shfl.sync.bfly.b32	%r78, %r77, 2, 31, -1;
	selp.b32 	%r79, %r63, %r78, %p1;
	selp.b32 	%r80, %r78, %r71, %p1;
	selp.b32 	%r81, %r75, %r67, %p1;
	shfl.sync.bfly.b32	%r82, %r81, 2, 31, -1;
	selp.b32 	%r83, %r67, %r82, %p1;
	selp.b32 	%r84, %r82, %r75, %p1;
	selp.b32 	%r85, %r72, %r64, %p1;
	shfl.sync.bfly.b32	%r86, %r85, 2, 31, -1;
	selp.b32 	%r87, %r64, %r86, %p1;
	selp.b32 	%r88, %r86, %r72, %p1;
	selp.b32 	%r89, %r76, %r68, %p1;
	shfl.sync.bfly.b32	%r90, %r89, 2, 31, -1;
	selp.b32 	%r91, %r68, %r90, %p1;
	selp.b32 	%r92, %r90, %r76, %p1;
	or.b32  	%r93, %r4, %r100;
	shl.b32 	%r94, %r93, 14;
	or.b32  	%r95, %r94, %r5;
	cvt.u64.u32 	%rd10, %r95;
	add.s64 	%rd11, %rd2, %rd10;
	st.global.v4.u32 	[%rd11], {%r79, %r83, %r87, %r91};
	shl.b32 	%r96, %r93, 12;
	or.b32  	%r97, %r6, %r96;
	or.b32  	%r98, %r97, 8192;
	mul.wide.s32 	%rd12, %r98, 4;
	add.s64 	%rd13, %rd2, %rd12;
	st.global.v4.u32 	[%rd13], {%r80, %r84, %r88, %r92};
	add.s32 	%r101, %r101, 1;
	add.s32 	%r100, %r100, 16;
	setp.ne.s32 	%p3, %r101, 256;
	@%p3 bra 	LBB0_1;
// %bb.2:                               // %L1170
	mov.u32 	%r99, 0;
	st.global.u32 	[%rd3], %r99;
	ret;
                                        // -- End function
}
